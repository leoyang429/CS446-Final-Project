{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CS446 Final Project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/gist/leoyang429/bdba9312049f5d1b940f9cd8ab4c5211/cs446-final-project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2r69G1gYEXr"
      },
      "source": [
        "# Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MqW3ZToYfANw"
      },
      "source": [
        "from google.colab import drive\r\n",
        "from matplotlib import pyplot as plt\r\n",
        "from google.colab import auth\r\n",
        "\r\n",
        "import os\r\n",
        "import numpy as np  \r\n",
        "import re, time\r\n",
        "import tensorflow as tf\r\n",
        "import random\r\n",
        "import math\r\n",
        "from tensorflow import keras\r\n",
        "\r\n",
        "import argparse\r\n",
        "import pandas as pd\r\n",
        "\r\n",
        "from glob import glob\r\n",
        "from tqdm import tqdm\r\n",
        "from keras import backend as K\r\n",
        "\r\n",
        "import tensorflow as tf\r\n",
        "from tensorflow import keras\r\n",
        "from keras.layers import Conv3D, MaxPool3D, Flatten, UpSampling3D, BatchNormalization\r\n",
        "from keras.models import *\r\n",
        "from keras.layers import *\r\n",
        "from keras.optimizers import *\r\n",
        "from keras.utils import to_categorical"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WDLDu5JF99CV"
      },
      "source": [
        "# Mount to Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYBDWIq9-Bhg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58513608-ec50-4aa5-d7f5-da36d439ddc0"
      },
      "source": [
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vaOsfJIS1CAc"
      },
      "source": [
        "# Enable GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ocUxlBJV1Ean",
        "outputId": "65381476-2b4e-4131-84f7-f093b1c43352"
      },
      "source": [
        "%tensorflow_version 2.x\r\n",
        "import tensorflow as tf\r\n",
        "device_name = tf.test.gpu_device_name()\r\n",
        "if device_name != '/device:GPU:0':\r\n",
        "  raise SystemError('GPU device not found')\r\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cz-j26rwuSeo"
      },
      "source": [
        "gpu_info = !nvidia-smi\r\n",
        "gpu_info = '\\n'.join(gpu_info)\r\n",
        "if gpu_info.find('failed') >= 0:\r\n",
        "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\r\n",
        "  print('and then re-execute this cell.')\r\n",
        "else:\r\n",
        "  print(gpu_info)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "faIRdMq7AW2e"
      },
      "source": [
        "# 3D UNET-like CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WHoHfpoNjg2d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0959357d-96a8-450b-f49b-48bb982ec823"
      },
      "source": [
        "img_type_num = 4\r\n",
        "seg_class_num = 4\r\n",
        "h_padded = 160 #150\r\n",
        "w_padded = 208 #194\r\n",
        "d_padded = 176 #164\r\n",
        "\r\n",
        "smooth = 0.000001\r\n",
        "\r\n",
        "max_epoch = 100\r\n",
        "train_num = 204\r\n",
        "batch_size = 2\r\n",
        "dataset = np.load('/content/drive/My Drive/Colab Notebooks/data_pub.zip')\r\n",
        "entries = list(dataset)\r\n",
        "entries.sort()\r\n",
        "print(entries[410])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "validation/001_imgs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GG7L_TIzYXWq"
      },
      "source": [
        "def dice_coefficient(y_true, y_pred):\n",
        "  dc = []\n",
        "  for i in range(seg_class_num):\n",
        "    y_true_f = K.flatten(y_true[:,:,:,:,i])\n",
        "    y_pred_f = K.flatten(y_pred[:,:,:,:,i])\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "\n",
        "    dc.append((2.0 * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth))\n",
        "\n",
        "  return tf.add_n(dc)/seg_class_num\n",
        "\n",
        "def dice_coefficient_loss(y_true, y_pred):\n",
        "    return 1-dice_coefficient(y_true, y_pred)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WX-bd2b9ht4k"
      },
      "source": [
        "def unet(input_size = (h_padded, w_padded, d_padded, img_type_num)):\r\n",
        "  inputs = Input(input_size)\r\n",
        "\r\n",
        "  bn = BatchNormalization()(inputs)\r\n",
        "  conv1 = Conv3D(8, 3, activation = 'tanh', padding = 'same', kernel_initializer = 'he_normal')(bn)\r\n",
        "  pool1 = MaxPooling3D(pool_size=(2, 2, 2))(conv1)\r\n",
        "  conv2 = Conv3D(32, 3, activation = 'tanh', padding = 'same', kernel_initializer = 'he_normal')(pool1)\r\n",
        "  conv2 = Conv3D(32, 3, activation = 'tanh', padding = 'same', kernel_initializer = 'he_normal')(conv2)\r\n",
        "\r\n",
        "\r\n",
        "  pool2 = MaxPooling3D(pool_size=(2, 2, 2))(conv2)\r\n",
        "  conv3 = Conv3D(128, 3, activation = 'tanh', padding = 'same', kernel_initializer = 'he_normal')(pool2)\r\n",
        "  conv3 = Conv3D(128, 3, activation = 'tanh', padding = 'same', kernel_initializer = 'he_normal')(conv3)\r\n",
        "\r\n",
        "\r\n",
        "  pool3 = MaxPooling3D(pool_size=(2, 2, 2))(conv3)\r\n",
        "  conv4 = Conv3D(256, 3, activation = 'tanh', padding = 'same', kernel_initializer = 'he_normal')(pool3)\r\n",
        "  conv4 = Conv3D(256, 3, activation = 'tanh', padding = 'same', kernel_initializer = 'he_normal')(conv4)\r\n",
        "\r\n",
        "  drop4 = Dropout(0.2)(conv4)\r\n",
        "\r\n",
        "  pool4 = MaxPooling3D(pool_size=(2, 2, 2))(drop4)\r\n",
        "  conv5 = Conv3D(384, 3, activation = 'tanh', padding = 'same', kernel_initializer = 'he_normal')(pool4)\r\n",
        "  conv5 = Conv3D(384, 3, activation = 'tanh', padding = 'same', kernel_initializer = 'he_normal')(conv5)\r\n",
        "\r\n",
        "  drop5 = Dropout(0.2)(conv5)\r\n",
        "\r\n",
        "  up6 = Conv3D(256, 3, activation = 'tanh', padding = 'same', kernel_initializer = 'he_normal')(UpSampling3D(size = (2,2,2))(drop5))\r\n",
        "  merge6 = concatenate([drop4,up6], axis = 4)\r\n",
        "  conv6 = Conv3D(256, 3, activation = 'tanh', padding = 'same', kernel_initializer = 'he_normal')(merge6)\r\n",
        "  conv6 = Conv3D(256, 3, activation = 'tanh', padding = 'same', kernel_initializer = 'he_normal')(conv6)\r\n",
        "\r\n",
        "\r\n",
        "  up7 = Conv3D(128, 3, activation = 'tanh', padding = 'same', kernel_initializer = 'he_normal')(UpSampling3D(size = (2,2,2))(conv6))\r\n",
        "  merge7 = concatenate([conv3,up7], axis = 4)\r\n",
        "  conv7 = Conv3D(128, 3, activation = 'tanh', padding = 'same', kernel_initializer = 'he_normal')(merge7)\r\n",
        "  conv7 = Conv3D(128, 3, activation = 'tanh', padding = 'same', kernel_initializer = 'he_normal')(conv7)\r\n",
        "\r\n",
        "\r\n",
        "  up8 = Conv3D(32, 3, activation = 'tanh', padding = 'same', kernel_initializer = 'he_normal')(UpSampling3D(size = (2,2,2))(conv7))\r\n",
        "  merge8 = concatenate([conv2,up8], axis = 4)\r\n",
        "  conv8 = Conv3D(32, 3, activation = 'tanh', padding = 'same', kernel_initializer = 'he_normal')(merge8)\r\n",
        "  conv8 = Conv3D(32, 3, activation = 'tanh', padding = 'same', kernel_initializer = 'he_normal')(conv8)\r\n",
        "\r\n",
        "\r\n",
        "  up9 = Conv3D(8, 3, activation = 'tanh', padding = 'same', kernel_initializer = 'he_normal')(UpSampling3D(size = (2,2,2))(conv8))\r\n",
        "  merge9 = concatenate([conv1,up9], axis = 4)\r\n",
        "  conv10 = Conv3D(8, 3, activation = 'tanh', padding = 'same', kernel_initializer = 'he_normal')(merge9)\r\n",
        "  conv11 = Conv3D(4, 3, activation = 'sigmoid', padding = 'same', kernel_initializer = 'he_normal')(conv10)\r\n",
        "  \r\n",
        "\r\n",
        "  model = Model(inputs = inputs, outputs = conv11)\r\n",
        "  model.compile(\"adam\", loss = dice_coefficient_loss, metrics=[dice_coefficient])\r\n",
        "\r\n",
        "  return model"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jyiNWacHrNOS"
      },
      "source": [
        "def train_gen():\r\n",
        "  for epoch in range(max_epoch):\r\n",
        "    train_img = np.zeros((batch_size, h_padded, w_padded, d_padded, img_type_num))\r\n",
        "    train_seg = np.zeros((batch_size, h_padded, w_padded, d_padded, seg_class_num))\r\n",
        "    sampler = list(range(0,204))\r\n",
        "    random.shuffle(sampler)\r\n",
        "    cnt = 0\r\n",
        "\r\n",
        "    batch_num = math.floor(train_num/batch_size)\r\n",
        "    for k in range(batch_num):\r\n",
        "      for i, j in zip(sampler[k*batch_size:(k+1)*batch_size], range(batch_size)):\r\n",
        "          cnt+=1\r\n",
        "          img = dataset[entries[2*i+1]]\r\n",
        "          img = np.moveaxis(img, 0, -1)\r\n",
        "          seg = dataset[entries[2*i+2]]\r\n",
        "\r\n",
        "          img, seg = padding(img, seg)\r\n",
        "          seg_onehot = seg_to_onehot(seg)\r\n",
        "\r\n",
        "          train_img[j] = img\r\n",
        "          train_seg[j] = seg_onehot\r\n",
        "      yield(train_img, train_seg)\r\n",
        "      \r\n",
        "    remaining_num = train_num - batch_num * batch_size\r\n",
        "    if remaining_num > 0:\r\n",
        "      train_img = np.zeros((remaining_num, h_padded, w_padded, d_padded, img_type_num))\r\n",
        "      train_seg = np.zeros((remaining_num, h_padded, w_padded, d_padded, seg_class_num))\r\n",
        "      for i, j in zip(sampler[batch_num * batch_size:], range(remaining_num)):\r\n",
        "          cnt+=1\r\n",
        "          img = dataset[entries[2*i+1]]\r\n",
        "          img = np.moveaxis(img, 0, -1)\r\n",
        "          seg = dataset[entries[2*i+2]]\r\n",
        "\r\n",
        "          img, seg = padding(img, seg)\r\n",
        "\r\n",
        "          seg_onehot = seg_to_onehot(seg)\r\n",
        "\r\n",
        "          train_img[j] = img\r\n",
        "          train_seg[j] = seg_onehot\r\n",
        "      yield(train_img, train_seg)\r\n",
        "    #print(cnt)\r\n",
        "    K.set_value(model.optimizer.learning_rate, 0.001*pow(0.85,epoch+1))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CvcsG5polelf"
      },
      "source": [
        "def seg_to_onehot(seg):\r\n",
        "  seg_onehot = to_categorical(seg.astype(int), num_classes=seg_class_num)\r\n",
        "  return seg_onehot"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkPZducsn5to"
      },
      "source": [
        "def padding(img, seg):\r\n",
        "  h_raw = img.shape[0]\r\n",
        "  w_raw = img.shape[1]\r\n",
        "  d_raw = img.shape[2]\r\n",
        "\r\n",
        "\r\n",
        "  h_pad = (int((h_padded - h_raw)/2), int((h_padded - h_raw + 1)/2))\r\n",
        "  w_pad = (int((w_padded - w_raw)/2), int((w_padded - w_raw + 1)/2))\r\n",
        "  d_pad = (int((d_padded - d_raw)/2), int((d_padded - d_raw + 1)/2))\r\n",
        "\r\n",
        "  img = np.pad(img, pad_width=(h_pad, w_pad, d_pad, (0, 0)), mode='constant', constant_values=0)\r\n",
        "  \r\n",
        "  seg = np.pad(seg, pad_width=(h_pad, w_pad, d_pad), mode='constant', constant_values=0)\r\n",
        "\r\n",
        "  return img, seg"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvOyqVdJrChs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 953
        },
        "outputId": "312eb6ff-d80f-40bc-a889-a9d1bedfee72"
      },
      "source": [
        "with tf.device('/device:GPU:0'):\r\n",
        "    model = unet()\r\n",
        "\r\n",
        "model.fit(train_gen(), steps_per_epoch = train_num / batch_size, epochs=max_epoch)\r\n",
        "\r\n",
        "model.save('/content/drive/My Drive/Colab Notebooks/model/unet_dice_gpu')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "102/102 [==============================] - 186s 2s/step - loss: 0.6469 - dice_coefficient: 0.3531\n",
            "Epoch 2/100\n",
            "102/102 [==============================] - 159s 2s/step - loss: 0.4055 - dice_coefficient: 0.5945\n",
            "Epoch 3/100\n",
            "102/102 [==============================] - 159s 2s/step - loss: 0.3258 - dice_coefficient: 0.6742\n",
            "Epoch 4/100\n",
            "102/102 [==============================] - 159s 2s/step - loss: 0.3231 - dice_coefficient: 0.6769\n",
            "Epoch 5/100\n",
            "102/102 [==============================] - 159s 2s/step - loss: 0.3127 - dice_coefficient: 0.6873\n",
            "Epoch 6/100\n",
            "102/102 [==============================] - 159s 2s/step - loss: 0.2870 - dice_coefficient: 0.7130\n",
            "Epoch 7/100\n",
            "102/102 [==============================] - 159s 2s/step - loss: 0.2923 - dice_coefficient: 0.7077\n",
            "Epoch 8/100\n",
            "102/102 [==============================] - 159s 2s/step - loss: 0.2805 - dice_coefficient: 0.7195\n",
            "Epoch 9/100\n",
            "102/102 [==============================] - 159s 2s/step - loss: 0.2826 - dice_coefficient: 0.7174\n",
            "Epoch 10/100\n",
            "102/102 [==============================] - 159s 2s/step - loss: 0.2859 - dice_coefficient: 0.7141\n",
            "Epoch 11/100\n",
            "102/102 [==============================] - 159s 2s/step - loss: 0.2824 - dice_coefficient: 0.7176\n",
            "Epoch 12/100\n",
            "102/102 [==============================] - 159s 2s/step - loss: 0.2721 - dice_coefficient: 0.7279\n",
            "Epoch 13/100\n",
            "102/102 [==============================] - 159s 2s/step - loss: 0.2787 - dice_coefficient: 0.7213\n",
            "Epoch 14/100\n",
            "102/102 [==============================] - 159s 2s/step - loss: 0.2766 - dice_coefficient: 0.7234\n",
            "Epoch 15/100\n",
            "102/102 [==============================] - 159s 2s/step - loss: 0.2743 - dice_coefficient: 0.7257\n",
            "Epoch 16/100\n",
            "102/102 [==============================] - 159s 2s/step - loss: 0.2816 - dice_coefficient: 0.7184\n",
            "Epoch 17/100\n",
            "  1/102 [..............................] - ETA: 2:36 - loss: 0.2409 - dice_coefficient: 0.7591"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-53c442fbb5d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_gen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_num\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/Colab Notebooks/model/unet_dice_gpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yxJ3mI8-aHI1"
      },
      "source": [
        "# Test on Validation Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvvjbupz53RP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4358fa09-1334-4ab1-a525-fd1afbb9a582"
      },
      "source": [
        "# with tf.device('/device:GPU:0'):\r\n",
        "#   model = keras.models.load_model('/content/drive/My Drive/Colab Notebooks/model/unet_dice_gpu')\r\n",
        "\r\n",
        "validate_num = 68\r\n",
        "validate_batch_num = 1\r\n",
        "\r\n",
        "validate_img = np.zeros((validate_batch_num, h_padded, w_padded, d_padded, img_type_num))\r\n",
        "validate_seg = []\r\n",
        "\r\n",
        "batchnum = math.floor(validate_num/validate_batch_num)\r\n",
        "\r\n",
        "total_dc = 0.0\r\n",
        "\r\n",
        "for k in range(batchnum):\r\n",
        "  #print('batch', k)\r\n",
        "  for i in range(validate_batch_num):\r\n",
        "      img = dataset[entries[2*validate_batch_num*k+2*i+410]]\r\n",
        "      img = np.moveaxis(img, 0, -1)\r\n",
        "      seg = dataset[entries[2*validate_batch_num*k+2*i+411]]\r\n",
        "      \r\n",
        "      shape = img.shape\r\n",
        "  \r\n",
        "      h_raw = shape[0]\r\n",
        "      w_raw = shape[1]\r\n",
        "      d_raw = shape[2]\r\n",
        "\r\n",
        "      h_pad = (int((h_padded - h_raw)/2), int((h_padded - h_raw + 1)/2))\r\n",
        "      w_pad = (int((w_padded - w_raw)/2), int((w_padded - w_raw + 1)/2))\r\n",
        "      d_pad = (int((d_padded - d_raw)/2), int((d_padded - d_raw + 1)/2))\r\n",
        "\r\n",
        "      seg = np.pad(seg, pad_width=(h_pad, w_pad, d_pad), mode='constant', constant_values=0)\r\n",
        "      actu_seg = seg[h_pad[0]:h_raw+h_pad[0], w_pad[0]:w_raw+w_pad[0], d_pad[0]:d_raw+d_pad[0]]\r\n",
        "      actu_seg = seg_to_onehot(actu_seg)\r\n",
        "      actu_seg = tf.expand_dims(actu_seg,0)\r\n",
        "\r\n",
        "      img = np.pad(img, pad_width=(h_pad, w_pad, d_pad, (0, 0)), mode='constant', constant_values=0)\r\n",
        "\r\n",
        "      img = tf.expand_dims(img, 0)\r\n",
        "\r\n",
        "      seg_hat = model.predict(img)\r\n",
        "\r\n",
        "      actu_seg_hat = seg_hat[0,h_pad[0]:h_raw+h_pad[0], w_pad[0]:w_raw+w_pad[0], d_pad[0]:d_raw+d_pad[0]]\r\n",
        "      actu_seg_hat = tf.expand_dims(actu_seg_hat,0)\r\n",
        "\r\n",
        "      dc = dice_coefficient(actu_seg, actu_seg_hat)\r\n",
        "      total_dc += dc\r\n",
        "\r\n",
        "print(\"Average Dice Coefficient on Validation Set:\", total_dc/validate_num)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average Dice Coefficient on Validation Set: tf.Tensor(0.66537577, shape=(), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZKKmdC6C5pg"
      },
      "source": [
        "# Testing & Encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qNza8ymOL5ng"
      },
      "source": [
        "def rlencode(x, dropna=False):\r\n",
        "    \"\"\"\r\n",
        "    Run length encoding.\r\n",
        "    Based on http://stackoverflow.com/a/32681075, which is based on the rle \r\n",
        "    function from R.\r\n",
        "    \r\n",
        "    Parameters\r\n",
        "    ----------\r\n",
        "    x : 1D array_like\r\n",
        "        Input array to encode\r\n",
        "    dropna: bool, optional\r\n",
        "        Drop all runs of NaNs.\r\n",
        "    \r\n",
        "    Returns\r\n",
        "    -------\r\n",
        "    start positions, run lengths, run values\r\n",
        "    \r\n",
        "    \"\"\"\r\n",
        "    where = np.flatnonzero\r\n",
        "    x = np.asarray(x)\r\n",
        "    n = len(x)\r\n",
        "    if n == 0:\r\n",
        "                return (np.array([], dtype=int), \r\n",
        "                        np.array([], dtype=int), \r\n",
        "                        np.array([], dtype=x.dtype))\r\n",
        "\r\n",
        "    starts = np.r_[0, where(~np.isclose(x[1:], x[:-1], equal_nan=True)) + 1]\r\n",
        "    lengths = np.diff(np.r_[starts, n])\r\n",
        "    values = x[starts]\r\n",
        "    \r\n",
        "    if dropna:\r\n",
        "        mask = ~np.isnan(values)\r\n",
        "        starts, lengths, values = starts[mask], lengths[mask], values[mask]\r\n",
        "    \r\n",
        "    return starts, lengths, values"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJpLLXJMEd5K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c7f7e2c-ea2d-496a-bf85-3347e1e39e1a"
      },
      "source": [
        "# with tf.device('/device:GPU:0'):\r\n",
        "#   model = keras.models.load_model('/content/drive/My Drive/Colab Notebooks/model/unet_dice_gpu')\r\n",
        "\r\n",
        "dataset = np.load('/content/drive/My Drive/Colab Notebooks/test_pub.zip')\r\n",
        "entries = list(dataset)\r\n",
        "entries.sort()\r\n",
        "print(entries)\r\n",
        "\r\n",
        "test_case_num = 68\r\n",
        "\r\n",
        "for i in range(test_case_num):\r\n",
        "  img = dataset[entries[i+1]]\r\n",
        "  img = np.moveaxis(img, 0, -1)\r\n",
        "  #print(i)\r\n",
        "\r\n",
        "  shape = img.shape\r\n",
        "  \r\n",
        "  h_raw = shape[0]\r\n",
        "  w_raw = shape[1]\r\n",
        "  d_raw = shape[2]\r\n",
        "\r\n",
        "  h_pad = (int((h_padded - h_raw)/2), int((h_padded - h_raw + 1)/2))\r\n",
        "  w_pad = (int((w_padded - w_raw)/2), int((w_padded - w_raw + 1)/2))\r\n",
        "  d_pad = (int((d_padded - d_raw)/2), int((d_padded - d_raw + 1)/2))\r\n",
        "\r\n",
        "  img = np.pad(img, pad_width=(h_pad, w_pad, d_pad, (0, 0)), mode='constant', constant_values=0)\r\n",
        "\r\n",
        "  img = tf.expand_dims(img, 0)\r\n",
        "\r\n",
        "  seg = model.predict(img)\r\n",
        "\r\n",
        "  actu_seg = np.argmax(seg[0,h_pad[0]:h_raw+h_pad[0], w_pad[0]:w_raw+w_pad[0], d_pad[0]:d_raw+d_pad[0]], axis=3)\r\n",
        "  #print(actu_seg[70, 70])\r\n",
        "  np.save(\"/content/drive/My Drive/Colab Notebooks/test_seg/0\"+str((i+1)//10)+str((i+1)%10)+\"_seg.npy\", actu_seg)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['test_pub/', 'test_pub/001_imgs', 'test_pub/002_imgs', 'test_pub/003_imgs', 'test_pub/004_imgs', 'test_pub/005_imgs', 'test_pub/006_imgs', 'test_pub/007_imgs', 'test_pub/008_imgs', 'test_pub/009_imgs', 'test_pub/010_imgs', 'test_pub/011_imgs', 'test_pub/012_imgs', 'test_pub/013_imgs', 'test_pub/014_imgs', 'test_pub/015_imgs', 'test_pub/016_imgs', 'test_pub/017_imgs', 'test_pub/018_imgs', 'test_pub/019_imgs', 'test_pub/020_imgs', 'test_pub/021_imgs', 'test_pub/022_imgs', 'test_pub/023_imgs', 'test_pub/024_imgs', 'test_pub/025_imgs', 'test_pub/026_imgs', 'test_pub/027_imgs', 'test_pub/028_imgs', 'test_pub/029_imgs', 'test_pub/030_imgs', 'test_pub/031_imgs', 'test_pub/032_imgs', 'test_pub/033_imgs', 'test_pub/034_imgs', 'test_pub/035_imgs', 'test_pub/036_imgs', 'test_pub/037_imgs', 'test_pub/038_imgs', 'test_pub/039_imgs', 'test_pub/040_imgs', 'test_pub/041_imgs', 'test_pub/042_imgs', 'test_pub/043_imgs', 'test_pub/044_imgs', 'test_pub/045_imgs', 'test_pub/046_imgs', 'test_pub/047_imgs', 'test_pub/048_imgs', 'test_pub/049_imgs', 'test_pub/050_imgs', 'test_pub/051_imgs', 'test_pub/052_imgs', 'test_pub/053_imgs', 'test_pub/054_imgs', 'test_pub/055_imgs', 'test_pub/056_imgs', 'test_pub/057_imgs', 'test_pub/058_imgs', 'test_pub/059_imgs', 'test_pub/060_imgs', 'test_pub/061_imgs', 'test_pub/062_imgs', 'test_pub/063_imgs', 'test_pub/064_imgs', 'test_pub/065_imgs', 'test_pub/066_imgs', 'test_pub/067_imgs', 'test_pub/068_imgs']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rXoz5hV5ae06",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7acb80c-3b1c-44ef-bca6-b61b0f53d484"
      },
      "source": [
        "# get all the npy files in folder\r\n",
        "SEP = os.path.sep\r\n",
        "files = glob(\"/content/drive/My Drive/Colab Notebooks/test_seg/*\")\r\n",
        "\r\n",
        "ids = []    # ImageId_ClassId columns\r\n",
        "codes = []  # EncodedPixels columns\r\n",
        "\r\n",
        "# iterate through the entire folders. Compute the run-length encoding for each segmenation npy file\r\n",
        "for i, file in enumerate(tqdm(files)):\r\n",
        "    # check if the file is seg (exclude img npy file)\r\n",
        "    # npy file name are expected to have the format of XXX_seg.npy\r\n",
        "    if not file.split(SEP)[-1][-7:-4] == 'seg':\r\n",
        "        continue\r\n",
        "\r\n",
        "    # im_name are expected to have the format of XXX_seg.npy\r\n",
        "    im_name = file.split(SEP)[-1][:3]\r\n",
        "    sample = np.load(file).flatten() # flatten the numpy array to 1d\r\n",
        "    \r\n",
        "    # get the start position, \r\n",
        "    # length for each segment correspoding to start position, \r\n",
        "    # and the value/labels for each segments\r\n",
        "    starts, lengths, values = rlencode(sample)\r\n",
        "\r\n",
        "    # these will be the encoded pixels strings for each image, 4 labels for each iamge\r\n",
        "    code_1 = ''\r\n",
        "    code_2 = ''\r\n",
        "    code_3 = ''\r\n",
        "    code_4 = ''\r\n",
        "    # convert the run-length encoding output from rlencode function to the required csv format\r\n",
        "    for start, length, value in zip(starts, lengths, values):\r\n",
        "        if value == 0:\r\n",
        "            code_1 += '{} {} '.format(start, length)\r\n",
        "        elif value == 1:\r\n",
        "            code_2 += '{} {} '.format(start, length)\r\n",
        "        elif value == 2:\r\n",
        "            code_3 += '{} {} '.format(start, length)\r\n",
        "        elif value == 3:\r\n",
        "            code_4 += '{} {} '.format(start, length)\r\n",
        "\r\n",
        "    # update final output list, add for rows for each image (4 labels)\r\n",
        "    for i in range(4):\r\n",
        "        id = '{}_{}'.format(im_name, i)\r\n",
        "        ids.append(id)\r\n",
        "    codes.extend([code_1.strip(), code_2.strip(), code_3.strip(), code_4.strip()])\r\n",
        "\r\n",
        "\r\n",
        "dic = {'ImageId_ClassId': ids, 'EncodedPixels': codes}\r\n",
        "df = pd.DataFrame(dic)\r\n",
        "df.to_csv(\"/content/drive/My Drive/Colab Notebooks/test_seg/submission.csv\", index=False)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 69/69 [00:06<00:00, 10.11it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}